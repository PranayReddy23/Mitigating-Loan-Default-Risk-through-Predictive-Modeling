{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e69d647-3f31-438a-84c9-09941436da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3711d77b-b654-4b79-b889-004c5addfe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"LoanData.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd219fe-0692-4607-a8ea-b91079f60702",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec4f3b5-7527-4245-b6cf-d2705a977796",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d67b7b3-6e1b-45f0-90b7-9e2eb478ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'ed':'education_level'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bc0988-19ff-4330-83e0-67b9e7d8e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6f2800-4161-44e9-957d-b3cabe539e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['age', 'education_level', 'employ', 'address', 'income', 'debtinc',\n",
    "       'creddebt', 'othdebt']\n",
    "\n",
    "for i in columns:\n",
    "    print(i,':',df[i].min())\n",
    "    print(i,':',df[i].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39573ef-83d8-4a0a-8822-e7882d7a1e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d766787b-de05-493b-981d-5095dd2e9ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education_level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c668500-1ca5-4a93-8624-60a5c5558adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d5fe06-0cf3-46be-bcc3-689d71ba4871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['employ'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f5a1c-ddbf-4060-9783-3578f5d000a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['address'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20b9cb-b8dd-492d-b25d-ef60563e8fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['default'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020937a3-af17-4f08-ae17-e8eeb551bfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['default'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc05393-328a-4677-b00e-25c08e971dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "continous = ['age', 'education_level', 'employ', 'address', 'income', 'debtinc',\n",
    "       'creddebt', 'othdebt']\n",
    "discrete_categorical = ['default']\n",
    "discrete_count = ['education_level', 'employ', 'address']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152e3496-5c74-4571-94e2-2a7abeb8630d",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a14b8c-9c77-440c-83c2-4a5003bd308b",
   "metadata": {},
   "source": [
    "### For continous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3ed501-5a32-4ffd-9859-45b82c016f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[continous].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c783911-1673-4107-99c8-c2b97c1add44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[continous].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16305af-b53f-4b75-9937-b29f2b8102dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485c1c47-6def-4d77-ac06-05176b8f3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['age','income','debtinc','creddebt','othdebt']\n",
    "plt.rcParams['figure.figsize'] = (18,10)\n",
    "for i,col in enumerate(cols, start=1):\n",
    "    plt.subplot(2,3,i)\n",
    "    sns.histplot(df[col],kde=True)\n",
    "    \n",
    "plt.suptitle(\"Univariate Analysis on Numerical Columns\")\n",
    "#plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0bf3fd-9f5f-449d-989a-b9a9fed843cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[continous])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897fe3f-5ca3-4146-be96-fe3b3798e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df[continous].corr(), annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d47a741-0af5-4cda-89e3-4b676512a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[continous].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbb83ab-eaef-4d68-9f7f-8e86c6b5cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcols = ['age','income','debtinc','creddebt','othdebt']\n",
    "\n",
    "for i, col in enumerate(outcols, start=1):\n",
    "    plt.subplot(2,3,i)\n",
    "    sns.boxplot(df[col])\n",
    "    plt.title(col)\n",
    "    \n",
    "plt.suptitle(\"Outliers in the Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02fca3d-c862-4adf-88e0-4b4b87291117",
   "metadata": {},
   "source": [
    "### For discrete variabls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7eb1b0-47e4-4d2f-81a9-aed643d99d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[discrete_categorical].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5fa79e-2a7d-496b-9181-3c836d763a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcols = ['education_level', 'employ', 'address']\n",
    "plt.rcParams['figure.figsize'] = (18,5)\n",
    "for i, col in enumerate(outcols, start=1):\n",
    "    plt.subplot(1,3,i)\n",
    "    sns.histplot(df[col], kde = True)\n",
    "    plt.title(col)\n",
    "    \n",
    "plt.suptitle(\"Discrete variable analysis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e870d811-93c6-41d6-b0e5-fca3a4eaad55",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d638f0c6-ddfd-4d3b-b1f3-9ed4469b2900",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['default'] = df['default'].replace({'1':1, '0':0, \"'0'\":0, ':0':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f626d8a-dd4b-4407-8887-2f3f3dc15ff2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['default'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc210f-4ab1-4426-823c-8d74b95a6a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['age_group'] = pd.cut(df['age'], bins=[0, 12, 18, 35, 60, 137], labels=['child', 'teen', 'young_adult', 'adult', 'senior'])\n",
    "#df.drop(columns = 'age', inplace = True)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04fc8a8-4bb5-44e2-a220-50f79e69b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65571c73-84e8-41c4-ad13-0183333f2f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "df[['income']] = imputer.fit_transform(df[['income']])\n",
    "df[['age']] = imputer.fit_transform(df[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d01ba9-11a8-4431-9ec0-7c5e57c8c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2364afb4-6f82-4c32-8367-b6433c03f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_value = df['education_level'].mode()[0]\n",
    "df['education_level'].fillna(mode_value, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c35740-39c7-4824-bd2b-b0e957123a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education_level'].replace(5.0, 1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa296331-cda8-472b-b64d-543ce71812c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['education_level'] = df['education_level'].astype('category')\n",
    "#df['education_level'] = df['education_level'].cat.rename_categories({1: 'High School', 2: 'Undergraduate', 3: 'Graduate', 4: 'Postgraduate'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5608638-45e0-44fc-bd89-b0c89e57541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_debt'] = df['creddebt'] + df['othdebt']\n",
    "df['debt_to_income_ratio'] = df['total_debt'] / df['income']\n",
    "df['employ_to_age_ratio'] = df['employ'] / df['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bda0511-399c-4b2d-8276-500945de80ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features= ['employ', 'debtinc', 'debt_to_income_ratio', 'employ_to_age_ratio']\n",
    "for i, feature1 in enumerate(selected_features):\n",
    "    for feature2 in selected_features[i+1:]:\n",
    "        df[f'{feature1}_x_{feature2}'] = df[feature1] * df[feature2]\n",
    "\n",
    "#Create polynomial features (degree=2)\n",
    "for feature in selected_features:\n",
    "    df[f'{feature}_squared'] = df[feature] ** 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3aaf6b-5479-47f1-8eed-5918bf425580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by `employ` and calculate mean and median of `debt_to_income_ratio`\n",
    "agg_stats = df.groupby('employ')['debt_to_income_ratio'].agg(['mean', 'median'])\n",
    "agg_stats.columns = ['mean_debt_to_income_by_employ', 'median_debt_to_income_by_employ']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d205d148-97c2-4d0f-befd-c5d4cae027e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(agg_stats, on='employ', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e39cdc-0172-4443-8c9f-398e3a7302d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b5e27d-d994-46a2-8033-cffc58bbdfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['age_group'] = df['age_group'].fillna(df['age_group'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9752ae-58d5-4474-8ab9-95143ce2b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#df = pd.get_dummies(df, columns=['education_level'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687b540-2afd-47e9-94b0-083f3c814dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.get_dummies(df, columns=['age_group'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6c7047-6d7d-4bda-a1fd-3544b3babf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfba8e6-995f-48c0-8535-fbe6562199ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outcols = ['age', 'education_level', 'employ', 'address', 'income', 'debtinc',\n",
    "       'creddebt', 'othdebt', 'total_debt', 'debt_to_income_ratio',\n",
    "       'employ_to_age_ratio']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(20, 30))\n",
    "axes = axes.flatten()\n",
    "for i, col in enumerate(outcols):\n",
    "    if col in df.columns:\n",
    "        sns.boxplot(y=df[col], ax=axes[i])\n",
    "        axes[i].set_title(f'Boxplot of {col}')\n",
    "        axes[i].set_xlabel('')\n",
    "    else:\n",
    "        axes[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d06e2f5-7ce2-4d83-b2cb-ac09e4710024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#continous_variables = ['age', 'employ', 'address', 'income', 'debtinc',\n",
    "#           'creddebt', 'othdebt', 'total_debt', 'debt_to_income_ratio',\n",
    "#           'employ_to_age_ratio', 'employ_x_debtinc',\n",
    "#           'employ_x_debt_to_income_ratio', 'employ_x_employ_to_age_ratio',\n",
    "#           'debtinc_x_debt_to_income_ratio', 'debtinc_x_employ_to_age_ratio',\n",
    "#           'debt_to_income_ratio_x_employ_to_age_ratio', 'employ_squared',\n",
    "#           'debtinc_squared', 'debt_to_income_ratio_squared',\n",
    "#           'employ_to_age_ratio_squared', 'mean_debt_to_income_by_employ',\n",
    "#           'median_debt_to_income_by_employ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc472d-00cf-4ddc-9024-cbf16fe68c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc43997-025b-4de7-b45d-b9f605802a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "columns_to_transform = ['age', 'employ', 'address', 'income', 'debtinc',\n",
    "       'creddebt', 'othdebt', 'total_debt', 'debt_to_income_ratio',\n",
    "       'employ_to_age_ratio']\n",
    "transform_info = {}\n",
    "# Apply Yeo-Johnson transformation to each column and calculate skewness\n",
    "for col in columns_to_transform:\n",
    "    df[col], lambda_value = stats.yeojohnson(df[col])\n",
    "    skewness = df[col].skew()\n",
    "    transform_info[col] = {'lambda': lambda_value, 'skewness': skewness}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c2cb4-5d3a-4f64-bfc2-337d4f691a13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f3a525-03f9-4e51-abfb-7256f3176aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2954911d-a95d-4c33-bb4d-0671855f3771",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cap_outliers(series, lower_percentile=1, upper_percentile=99):\n",
    "    lower_bound = series.quantile(lower_percentile / 100)\n",
    "    upper_bound = series.quantile(upper_percentile / 100)\n",
    "    return np.clip(series, lower_bound, upper_bound)\n",
    "\n",
    "# Define the numerical columns to be scaled\n",
    "num_cols = ['age','employ', 'address', 'income', 'debtinc',\n",
    "       'creddebt', 'othdebt', 'default', 'total_debt', 'debt_to_income_ratio',\n",
    "       'employ_to_age_ratio']\n",
    "\n",
    "\n",
    "# Cap outliers in the scaled numerical columns\n",
    "for col in num_cols:\n",
    "    df[col] = cap_outliers(df[col])\n",
    "\n",
    "\n",
    "# Visualize the final transformed features\n",
    "for col in num_cols:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f'Distribution of {col} after Scaling, Capping, and Log Transformation')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Boxplot of {col} after Scaling, Capping, and Log Transformation')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Print the first few rows to check the transformations\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4322f78a-5337-4229-95d2-f725b4673159",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df['age'].astype(int)\n",
    "df['education_level'] = df['education_level'].astype(int)\n",
    "df['employ'] = df['employ'].astype(int)\n",
    "df['address'] = df['address'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f6ce48-f818-41fe-98e6-91dd95c19850",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('default', axis = 1)\n",
    "y = df['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9809f4c2-cdb7-446e-a606-65e75b1feec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af8721c-4445-477c-aeef-2cc20813502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cb214a-8594-4a0a-9459-3588d66de35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train_selected shape:\", X_train.shape)\n",
    "print(\"X_test_selected shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Print the distribution of target classes in train and test sets\n",
    "print(\"\\nDistribution of classes in y_train:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nDistribution of classes in y_test:\")\n",
    "print(y_test.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2d6416-205d-432c-b4cf-0b99285ac863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992ec322-cab0-40ea-a2e6-7c01d82da1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train_resampled.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a83d86-5e77-4659-90ab-7ec36ea8f1b1",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc514ad6-f72c-4b89-8bbf-3a1a327bd022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19c59f7-b12b-44e2-9270-5d82f8237d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "sc = StandardScaler()\n",
    "#mm = MinMaxScaler()\n",
    "#rs = RobustScaler()\n",
    "X_train_scaled = sc.fit_transform(X_train_resampled)\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab531a65-e965-4f9b-8d67-e1bb1213ad88",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba57184e-58a0-4670-835b-014294c029c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import PCA\n",
    "#pca = PCA(n_components=0.96)\n",
    "\n",
    "#X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "#X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62682835-30d5-4181-afb4-c536bdcd157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train_scaled,y_train_resampled)\n",
    "\n",
    "# prediction\n",
    "ypred_train = lr.predict(X_train_scaled)\n",
    "lr_ypred_test = lr.predict(X_test_scaled)\n",
    "lr_y_prob_test = lr.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Train accuracy:\",accuracy_score(y_train_resampled,ypred_train))\n",
    "print(\"Test Accuracy:\",accuracy_score(y_test,lr_ypred_test))\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"cross_val_score:\",cross_val_score(lr,X_train_scaled,y_train_resampled,cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97c7c19-1756-45a3-bf48-6e553dd53344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "print(classification_report(y_test, lr_ypred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849aa69e-4a9d-4e3c-9e4a-28f2db9fb999",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,lr_ypred_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cfa9c6-637c-4d7b-85eb-51a760757d0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, lr_ypred_test)\n",
    "plt.figure(figsize = (4,2))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap = 'Blues')\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ff5f2a-41e9-4f17-b552-770faa02f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9f4c34-7812-4b73-896a-5d9f0b60f08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,auc,RocCurveDisplay\n",
    "fpr, tpr, thresholds = roc_curve(y_test,lr_y_prob_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051cec75-d7f3-4d6c-8736-517d759f2323",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3842ff-e1ed-4fc2-890b-e2252e00dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_scaled,y_train_resampled)\n",
    "\n",
    "# prediction\n",
    "ypred_train = knn.predict(X_train_scaled)\n",
    "knn_ypred_test = knn.predict(X_test_scaled)\n",
    "knn_y_prob_test = knn.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"Train accuracy:\",accuracy_score(y_train_resampled,ypred_train))\n",
    "print(\"Test Accuracy:\",accuracy_score(y_test,knn_ypred_test))\n",
    "\n",
    "print(\"cross_val_score:\",cross_val_score(knn,X_train_scaled,y_train_resampled,cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf2cec9-7c47-477d-8d75-16b8b4b17988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "estimator = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors':list(range(1,50))}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "cv_classifier = GridSearchCV(estimator,param_grid,cv=5,scoring='accuracy')\n",
    "\n",
    "cv_classifier.fit(X_train_scaled,y_train_resampled)\n",
    "cv_classifier.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a32053-a1ab-4310-8b7b-6df79ef0159e",
   "metadata": {},
   "source": [
    "### Finalizing the KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341bd230-c3db-4708-899a-860efcbd49af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train_scaled,y_train_resampled)\n",
    "\n",
    "# prediction\n",
    "ypred_train = knn.predict(X_train_scaled)\n",
    "knn_ypred_test = knn.predict(X_test_scaled)\n",
    "knn_y_prob_test = knn.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"Train accuracy:\",accuracy_score(y_train_resampled,ypred_train))\n",
    "print(\"Test Accuracy:\",accuracy_score(y_test,knn_ypred_test))\n",
    "\n",
    "print(\"cross_val_score:\",cross_val_score(knn,X_train_scaled,y_train_resampled,cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc9c0bb-ce80-4229-9501-8c294691b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
    "print(classification_report(y_test, knn_ypred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8802bb1b-e9bb-4191-a1ae-97ea5736ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, knn_ypred_test)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8927b542-63b9-40b6-84ba-b6bf1ba525bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, knn_ypred_test)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot = True, fmt = 'd', cmap = \"Blues\")\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642199a5-b68f-49b5-b2fb-04f2bbc69ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,auc,RocCurveDisplay\n",
    "fpr, tpr, thresholds = roc_curve(y_test,knn_y_prob_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3565d164-55e7-48c6-8b1f-dd75c1542136",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf08655-3ebf-405e-bfb8-15649c3bd62e",
   "metadata": {},
   "source": [
    "\n",
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe2c2f4-3a2b-41c4-aae4-aae316a496e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(probability=True)\n",
    "svm.fit(X_train_scaled,y_train_resampled)\n",
    "\n",
    "# prediction\n",
    "ypred_train = svm.predict(X_train_scaled)\n",
    "svc_ypred_test = svm.predict(X_test_scaled)\n",
    "svc_y_prob_test = svm.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"Train accuracy:\",accuracy_score(y_train_resampled,ypred_train))\n",
    "print(\"Test Accuracy:\",accuracy_score(y_test,svc_ypred_test))\n",
    "\n",
    "print(\"cross_val_score:\",cross_val_score(svm,X_train_scaled,y_train_resampled,cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a0d7b-203e-4a44-8e24-c65e42d2313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "# 3. Parameter Grid (Key hyperparameters to tune)\n",
    "param_grid = {\n",
    "    'C': [0.5, 1, 5],               # Explore a wider range with smaller values\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto'] + [0.001, 0.01, 0.1],   # Focus on smaller gamma values for RBF\n",
    "}\n",
    "\n",
    "\n",
    "# 4. Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# 5. Best Model & Results\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "# 6. Evaluate on Test Set\n",
    "best_svc = grid_search.best_estimator_\n",
    "y_pred = best_svc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f01183b-d171-4d7f-9e43-dbc435fa46a0",
   "metadata": {},
   "source": [
    "### Finalizing the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33eb72b-dc3c-4baf-aab3-74981bddf5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(probability=True, C=0.8 ,gamma = 0.1, kernel = 'rbf')\n",
    "#svm = SVC(probability=True, C = 0.5308342600258237, gamma = 0.5308342600258237, kernel = 'rbf')\n",
    "\n",
    "svm.fit(X_train_scaled,y_train_resampled)\n",
    "\n",
    "# prediction\n",
    "ypred_train = svm.predict(X_train_scaled)\n",
    "svc_ypred_test = svm.predict(X_test_scaled)\n",
    "svc_y_prob_test = svm.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"Train accuracy:\",accuracy_score(y_train_resampled,ypred_train))\n",
    "print(\"Test Accuracy:\",accuracy_score(y_test,svc_ypred_test))\n",
    "\n",
    "print(\"cross_val_score:\",cross_val_score(svm,X_train_scaled,y_train_resampled,cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca48ef-56c4-4ccb-bfc5-a7610a1cf5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
    "print(classification_report(y_test, svc_ypred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bcaf82-dda2-4e49-a943-3938993f98ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, svc_ypred_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c8d12e-16bf-4917-9dbc-0ae8ef571838",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, svc_ypred_test)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot = True, fmt = 'd', cmap = \"Blues\")\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc3bdd-9ad3-4656-9a79-f01507134032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,auc,RocCurveDisplay\n",
    "fpr, tpr, thresholds = roc_curve(y_test,svc_y_prob_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7861fce-478b-45a5-968a-6a624f84a0d2",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c74b01-c8a5-4d0b-b5b4-f1c27a256fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train_scaled,y_train_resampled)\n",
    "\n",
    "ypred_train = model.predict(X_train_scaled)\n",
    "ypred_test = model.predict(X_test_scaled)\n",
    "dt_y_prob_test = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Train Accuracy:\",accuracy_score(ypred_train,y_train_resampled))\n",
    "print(\"Test Accuracy:\",accuracy_score(ypred_test,y_test))\n",
    "print(\"Cross_val_score:\",cross_val_score(model,X_train_scaled,y_train_resampled,cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25145ce1-71d5-48b9-ac9e-11b3d695a88f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "\n",
    "# Your data (X_train, y_train) should be loaded here\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 30), # Start small, grow large\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "        'splitter': trial.suggest_categorical('splitter', ['best', 'random']),\n",
    "    }\n",
    "\n",
    "    model = DecisionTreeClassifier(**params)\n",
    "    scorer = make_scorer(accuracy_score) \n",
    "    score = cross_val_score(model, X_train_scaled, y_train_resampled, cv=5, scoring=scorer).mean()\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)  # Adjust as needed\n",
    "\n",
    "best_params = study.best_params\n",
    "best_score = study.best_value\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best accuracy:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd0d992-92f8-450d-a14a-18df9312e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(max_depth= 8, min_samples_split= 4, min_samples_leaf= 1, criterion= 'entropy', max_features= None, splitter= 'best')\n",
    "dt.fit(X_train_scaled,y_train_resampled)\n",
    "\n",
    "ypred_train = dt.predict(X_train_scaled)\n",
    "ypred_test = dt.predict(X_test_scaled)\n",
    "dt_y_prob_test = dt.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Train Accuracy:\",accuracy_score(ypred_train,y_train_resampled))\n",
    "print(\"Test Accuracy:\",accuracy_score(ypred_test,y_test))\n",
    "print(\"Cross_val_score:\",cross_val_score(dt,X_train_scaled,y_train_resampled,cv=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19953510-7380-44b9-aba9-847f53cc7a20",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c7fdbe-34cd-4c7c-bd97-e70891436cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_resampled,y_train_resampled)\n",
    "\n",
    "ypred_train = rf.predict(X_train_resampled)\n",
    "ypred_test = rf.predict(X_test)\n",
    "rf_y_prob_test = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Train Accuracy:\",accuracy_score(ypred_train,y_train_resampled))\n",
    "print(\"Test Accuracy:\",accuracy_score(ypred_test,y_test))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Cross_val_score:\",cross_val_score(rf,X_train_resampled,y_train_resampled,cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d7a62a-0b86-47f6-b9dc-0a1acd4126de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, make_scorer  \n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 15), \n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "        'ccp_alpha': trial.suggest_float('ccp_alpha', 1e-5, 1e-1, log=True),  # Cost complexity pruning\n",
    "        'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 2, 100)       # Limit leaf nodes\n",
    "    }\n",
    "    # Conditional sampling for max_samples\n",
    "    if params['bootstrap']:\n",
    "        params['max_samples'] = trial.suggest_uniform('max_samples', 0.6, 0.95)  # Tighter range\n",
    "    else:\n",
    "        params['max_samples'] = None \n",
    "\n",
    " \n",
    "    model = RandomForestClassifier(**params, random_state=42)\n",
    "    scorer = make_scorer(accuracy_score)\n",
    "    score = cross_val_score(model, X_train_resampled, y_train_resampled, cv=5, scoring=scorer).mean()\n",
    "    return score\n",
    "    \n",
    "    # Add a penalty for complex models\n",
    "    complexity_penalty = 0.01 * params['n_estimators'] + 0.05 * params['max_depth']\n",
    "    return score - complexity_penalty\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_score = study.best_value\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best accuracy:\", best_score)\n",
    "\n",
    "# ... (rest of the code as before)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c8c600-1d0f-47cb-8c89-d979cfb507e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)  # Set random_state for reproducibility\n",
    "\n",
    "# 3. Parameter Grid (Stronger regularization, varied tree depth/number)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],            # Try more trees\n",
    "    'max_depth': [None, 10, 15],               # Allow for deeper trees\n",
    "    'min_samples_split': [20, 30, 50],          # Slightly less restrictive splitting\n",
    "    'min_samples_leaf': [10, 15, 20],          # Slightly less restrictive leaves\n",
    "    'max_features': ['sqrt', 0.75, 'auto'],     # Consider more features\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "# 4. Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# 5. Best Model and Evaluation (Include test set accuracy for assessment)\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "y_pred_test = best_rf.predict(X_test_scaled)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Output (Always print to assess results, even if overfitting occurs)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989e30b2-9804-493d-bc04-45ef54ae9a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators= 241, max_depth= 10, min_samples_split= 4, min_samples_leaf= 1, max_features= 'log2', bootstrap= True, \n",
    "                            criterion= 'entropy', ccp_alpha= 0.0010399525940246316, max_leaf_nodes= 87, max_samples= 0.79545993040379)\n",
    "rf.fit(X_train_scaled,y_train_resampled)\n",
    "\n",
    "ypred_train = rf.predict(X_train_scaled)\n",
    "ypred_test = rf.predict(X_test_scaled)\n",
    "rf_y_prob_test = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Train Accuracy:\",accuracy_score(ypred_train,y_train_resampled))\n",
    "print(\"Test Accuracy:\",accuracy_score(ypred_test,y_test))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Cross_val_score:\",cross_val_score(rf,X_train_scaled,y_train_resampled,cv=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecab3366-f77a-46b2-94c8-883b466958ad",
   "metadata": {},
   "source": [
    "# Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6d7e43-72da-482c-8ef2-36da29b23de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abmodel = AdaBoostClassifier(n_estimators= 401, learning_rate= 0.9930119742426293)\n",
    "abmodel.fit(X_train_resampled,y_train_resampled)\n",
    "\n",
    "ypred_train = abmodel.predict(X_train_resampled)\n",
    "ypred_test = abmodel.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Train Accuracy:\",accuracy_score(y_train_resampled,ypred_train))\n",
    "print(\"Test Accuracty:\",accuracy_score(y_test,ypred_test))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"cross val score:\",cross_val_score(abmodel,X_train_resampled,y_train_resampled,cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef31c334-1f95-4650-84d0-ec036f16bb45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier  # Common base estimator for AdaBoost\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "\n",
    "# Your data (X_train, y_train) should be loaded here\n",
    "\n",
    "def objective(trial):\n",
    "    base_estimator = DecisionTreeClassifier(\n",
    "        max_depth=trial.suggest_int('max_depth', 1, 8),  \n",
    "        min_samples_split=trial.suggest_int('min_samples_split', 2, 20),\n",
    "        min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        ccp_alpha= trial.suggest_float('ccp_alpha', 1e-5, 1.0, log=True),  # Larger range\n",
    "        max_leaf_nodes= trial.suggest_int('max_leaf_nodes', 2, 20),\n",
    "    )\n",
    "    \n",
    "    # AdaBoost Parameters\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0, log=True), \n",
    "        'algorithm': trial.suggest_categorical('algorithm', ['SAMME', 'SAMME.R']),\n",
    "    }\n",
    "\n",
    "    model = AdaBoostClassifier(base_estimator, **params, random_state=42) # Corrected line\n",
    "    scorer = make_scorer(accuracy_score)\n",
    "    score = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring=scorer).mean()\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)  # Adjust as needed\n",
    "\n",
    "best_params = study.best_params\n",
    "best_score = study.best_value\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best accuracy:\", best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494ccd98-e024-4733-949e-b80a03a570b8",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7646665-d38b-490d-9bee-005b531f4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbmodel = GradientBoostingClassifier()\n",
    "gbmodel.fit(X_train,y_train)\n",
    "\n",
    "ypred_train = gbmodel.predict(X_train)\n",
    "ypred_test = gbmodel.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Train Accuracy:\",accuracy_score(y_train,ypred_train))\n",
    "print(\"Test Accuracty:\",accuracy_score(y_test,ypred_test))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"cross val score:\",cross_val_score(gbmodel,X_train,y_train,cv=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a594f56f-44c3-4059-95f8-61f779e13355",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99493dc1-b658-4f7c-9b7f-b78be110cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': [50, 100, 150],    \n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [2, 3, 4],            \n",
    "    'subsample': [0.7, 0.8, 0.9],      \n",
    "    'min_samples_split': [5, 10, 15],  \n",
    "    'min_samples_leaf': [2, 5, 10],    \n",
    "    'max_features': ['auto', 'sqrt'],  \n",
    "    'n_iter_no_change': [10, 20],      \n",
    "    'tol': [1e-4]\n",
    "}\n",
    "# Create a Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(random_state=42, validation_fraction=0.1, n_iter_no_change=10, tol=1e-4)\n",
    "# Create RandomizedSearchCV Object\n",
    "random_search = RandomizedSearchCV(\n",
    "    gb_clf, param_distributions=param_distributions, n_iter=20, cv=5, scoring='roc_auc', random_state=42\n",
    ")\n",
    "# Fit the model\n",
    "random_search.fit(X_train_scaled, y_train_resampled)\n",
    "# Print the best parameters and results\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best accuracy found: \", random_search.best_score_)\n",
    "y_pred = random_search.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, random_search.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(\"Best hyperparameters:\", random_search.best_estimator_.get_params())\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "\n",
    "scores = cross_val_score(random_search.best_estimator_, X_train_scaled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean CV score:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eca3a7-216c-4eab-b6d5-76964df275ab",
   "metadata": {},
   "source": [
    "### Finilaizing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab1090d-928c-40e4-93f9-cf79c36449b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbmodel = GradientBoostingClassifier(ccp_alpha= 0.0, criterion= 'friedman_mse', init= None, learning_rate= 0.1, loss= 'log_loss', \n",
    "                                     max_depth= 4, max_features= 'sqrt', max_leaf_nodes= None, min_impurity_decrease= 0.0, \n",
    "                                     min_samples_leaf= 5, min_samples_split= 15, min_weight_fraction_leaf= 0.0, n_estimators= 100,\n",
    "                                     n_iter_no_change= 20, random_state= 42,\n",
    "                                     subsample= 0.7, tol= 0.0001, validation_fraction= 0.1, verbose= 0, warm_start= False)\n",
    "gbmodel.fit(X_train_scaled,y_train_resampled)\n",
    "\n",
    "ypred_train = gbmodel.predict(X_train_scaled)\n",
    "ypred_test = gbmodel.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Train Accuracy:\",accuracy_score(y_train_resampled,ypred_train))\n",
    "print(\"Test Accuracty:\",accuracy_score(y_test,ypred_test))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"cross val score:\",cross_val_score(gbmodel,X_train_scaled,y_train_resampled,cv=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b069c6-95c8-4b47-bde7-9a7dab19395f",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88c2043-8a96-4d6c-a4ae-900e0c5d01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgbmodel = XGBClassifier()\n",
    "xgbmodel.fit(X_train_resampled,y_train_resampled)\n",
    "\n",
    "ypred_train = xgbmodel.predict(X_train_resampled)\n",
    "ypred_test = xgbmodel.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Train Accuracy:\",accuracy_score(y_train_resampled,ypred_train))\n",
    "print(\"Test Accuracty:\",accuracy_score(y_test,ypred_test))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"cross val score:\",cross_val_score(xgbmodel,X_train_resampled,y_train_resampled,cv=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9660976-3197-48b1-a9c5-07d641c586ba",
   "metadata": {},
   "source": [
    "### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f412e8-e025-4611-9e7c-dd018115fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cbbmodel = CatBoostClassifier()\n",
    "cbbmodel.fit(X_train_resampled,y_train_resampled)\n",
    "ypred_train = cbbmodel.predict(X_train_resampled)\n",
    "ypred_test = cbbmodel.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Train Accuracy:\",accuracy_score(y_train_resampled,ypred_train))\n",
    "print(\"Test Accuracty:\",accuracy_score(y_test,ypred_test))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"cross val score:\",cross_val_score(cbbmodel,X_train_resampled,y_train_resampled,cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0809ece8-c85f-4be2-8788-68ae95f575d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Accuracy:\",accuracy_score(y_train_resampled,ypred_train))\n",
    "print(\"Test Accuracty:\",accuracy_score(y_test,ypred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a7bb3a-0b57-43cb-9a2e-76bba4682a19",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5a324-2fe2-45b2-8173-05222231d31b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)  # Assuming one feature per time step\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# 2. Define Your CNN Model (with given parameters)\n",
    "model = keras.Sequential([\n",
    "    Conv1D(filters=128, kernel_size=5, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "\n",
    "    # Dense layers based on the given hyperparameters\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3002),  # Your value: 'dropout_0'\n",
    "\n",
    "    \n",
    "\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# 3. Compile and Train the Model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001922),  # Your value: 'learning_rate'\n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)  # Assuming you found 50 epochs optimal\n",
    "\n",
    "# 4. Evaluate the Model\n",
    "loss, accuracy, precision, recall = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "# 5. Generate Predictions and Confusion Matrix\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# 6. Visualize Confusion Matrix (Optional)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Not Default', 'Default'],\n",
    "            yticklabels=['Not Default', 'Default'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aacb01-d83a-4890-bfd1-6707d134cb15",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c1060c-6b54-4b58-8710-1ce362a251d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from kerastuner.tuners import RandomSearch \n",
    "\n",
    "# Function to build CNN model with tunable hyperparameters\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv1D(\n",
    "        filters=hp.Int('filters', min_value=32, max_value=512, step=32),\n",
    "        kernel_size=hp.Int('kernel_size', min_value=3, max_value=8, step=1),\n",
    "        activation='relu', input_shape=(X_train.shape[1], 1)\n",
    "    ))\n",
    "    model.add(keras.layers.MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # Add more Conv1D and MaxPooling1D layers if needed\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(\n",
    "        units=hp.Int('units', min_value=32, max_value=128, step=32),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(keras.layers.Dropout(rate=hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Create the tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',  # Metric to optimize\n",
    "    max_trials=20,            # Number of hyperparameter combinations to try\n",
    "    executions_per_trial=3,   # Number of models to train per combination (to reduce noise)\n",
    "    directory='my_dir',\n",
    "    project_name='loan_cnn_tuning'\n",
    "    overwrite = True \n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Start the search\n",
    "tuner.search(X_train_resampled, y_train_resampled, epochs=10, validation_data=(X_test, y_test), callbacks=[stop_early])\n",
    "\n",
    "# Get the best model and its hyperparameters\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters.values)\n",
    "\n",
    "# ... (Evaluate the best model on test data as before)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaed5112-d578-4a95-b7de-d2e9387cce50",
   "metadata": {},
   "source": [
    "# Final model with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18360ec5-a681-4fb5-8e94-dd3a940e0a34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build the CNN model with the provided best hyperparameters\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=384, kernel_size=5, activation='relu', padding='same', input_shape=(X_train.shape[1], 1)))  \n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=256, kernel_size=7, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "\n",
    "# Flatten before Dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense Layers (2 layers as per hyperparameters)\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.23003726126036944))  # Using the specific dropout rate\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.48827949663688364))  # Using the specific dropout rate\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.00018285893202451146),  # Use the specific learning rate\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model and store history\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=20, \n",
    "    batch_size=1024, \n",
    "    validation_data=(X_test, y_test)\n",
    ")\n",
    "\n",
    "# Evaluate on training and test sets (reshape back to 2D)\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Train Loss: {train_loss}, Train Accuracy: {train_acc}\")\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_acc}\")\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "\n",
    "# Generate classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d381c9c-dcef-445b-9495-f29394d17157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
